{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook is used to generate a csv file \n",
    "## CSV stores name of each test image and then includes information about it's predicitions (BBOX, LABEL, SCORE). \n",
    "### To be used to generate csv used in ensemble.py (for mulitple predictors - see 2nd to last cell) or simply in labels_to_text.py  (single predictor - see last cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import Packages\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import cv2\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gcc (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609\r\n",
      "Copyright (C) 2015 Free Software Foundation, Inc.\r\n",
      "This is free software; see the source for copying conditions.  There is NO\r\n",
      "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "import torch, torchvision\n",
    "torch.__version__\n",
    "!gcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_path = \"train\"\n",
    "valid_path = \"validation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Classes of amenities Airbnb mostly cares about\n",
    "subset = [\"Toilet\",\n",
    "          \"Swimming_pool\",\n",
    "          \"Bed\",\n",
    "          \"Billiard_table\",\n",
    "          \"Sink\",\n",
    "          \"Fountain\",\n",
    "          \"Oven\",\n",
    "          \"Ceiling_fan\",\n",
    "          \"Television\",\n",
    "          \"Microwave_oven\",\n",
    "          \"Gas_stove\",\n",
    "          \"Refrigerator\",\n",
    "          \"Kitchen_&_dining_room_table\",\n",
    "          \"Washing_machine\",\n",
    "          \"Bathtub\",\n",
    "          \"Stairs\",\n",
    "          \"Fireplace\",\n",
    "          \"Pillow\",\n",
    "          \"Mirror\",\n",
    "          \"Shower\",\n",
    "          \"Couch\",\n",
    "          \"Countertop\",\n",
    "          \"Coffeemaker\",\n",
    "          \"Dishwasher\",\n",
    "          \"Sofa_bed\",\n",
    "          \"Tree_house\",\n",
    "          \"Towel\",\n",
    "          \"Porch\",\n",
    "          \"Wine_rack\",\n",
    "          \"Jacuzzi\"]\n",
    "\n",
    "subset.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bathtub', 'Bed', 'Billiard table', 'Ceiling fan', 'Coffeemaker', 'Couch', 'Countertop', 'Dishwasher', 'Fireplace', 'Fountain', 'Gas stove', 'Jacuzzi', 'Kitchen & dining room table', 'Microwave oven', 'Mirror', 'Oven', 'Pillow', 'Porch', 'Refrigerator', 'Shower', 'Sink', 'Sofa bed', 'Stairs', 'Swimming pool', 'Television', 'Toilet', 'Towel', 'Tree house', 'Washing machine', 'Wine rack']\n"
     ]
    }
   ],
   "source": [
    "#Replaces underscores with spaces - matches airbnb classes with those from website\n",
    "for i in range(len(subset)):\n",
    "  subset[i] = subset[i].replace(\"_\", \" \")\n",
    "print(subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import CV2 for getting height & width of image\n",
    "import cv2\n",
    "\n",
    "# Import Detectron2 BoxMode for bounding boxes style\n",
    "from detectron2.structures import BoxMode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_json_labels(image_folder):\n",
    "    \"\"\"\n",
    "    Returns Detectron2 style labels of images in image_folder based on JSON label file in image_folder.\n",
    "    \n",
    "    TODO -- Maybe create some verbosity here? AKA, what are the outputs?\n",
    "    TODO -- what if annotations = None? Can we create a call to create an annotations CSV in 1 hit?\n",
    "    \n",
    "    Params\n",
    "    ------\n",
    "    image_folder (str): target folder containing images\n",
    "    \"\"\"\n",
    "    # Get absolute path of JSON label file\n",
    "    for file in os.listdir(image_folder):\n",
    "      if file.endswith(\".json\"):\n",
    "        json_file = os.path.join(image_folder, file)\n",
    "\n",
    "    # TODO: Fix this assertion\n",
    "    assert json_file, \"No .json label file found, please make one with annots_to_json()\"\n",
    "\n",
    "    with open(json_file, \"r\") as f:\n",
    "      img_dicts = json.load(f)\n",
    "\n",
    "    # Convert bbox_mode to Enum of BoxMode.XYXY_ABS (doesn't work loading normal from JSON)\n",
    "    for img_dict in img_dicts:\n",
    "      for annot in img_dict[\"annotations\"]:\n",
    "        annot[\"bbox_mode\"] = BoxMode.XYXY_ABS\n",
    "\n",
    "    return img_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valid_img_dicts = load_json_labels(\"validation\")\n",
    "train_img_dicts = load_json_labels(\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "\n",
    "def register_datasets(train_path, valid_path=None, target_classes=None):\n",
    "  \"\"\"\n",
    "  Registers a Detectron2 style dataset from training paths.\n",
    "\n",
    "  Params\n",
    "  ------\n",
    "  train_path (str) : pathname to training data containing training images\n",
    "  valid_path (str) : pathname to validation data containing validation images\n",
    "  \"\"\"\n",
    "  # TODO - update to accept any kind of path, e.g. not only coffeemaker, maybe could take a dict as input?\n",
    "  # E.g. {\"training\": \"path/to/training\",\n",
    "  #          \"valid\": \"path/to/valid\"}\n",
    "  for d in [train_path, valid_path]:\n",
    "    dataset_name = d.split(\"/\")[-1]\n",
    "    print(\"Registering: {}\".format(dataset_name))\n",
    "    DatasetCatalog.register(dataset_name, lambda d=d: load_json_labels(d))\n",
    "    MetadataCatalog.get(dataset_name).set(thing_classes=target_classes)\n",
    "  return MetadataCatalog.get(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metadata = register_datasets(train_path=train_path,\n",
    "                             valid_path=valid_path,\n",
    "                             target_classes=subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.config import get_cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Different Predictors and Config Files\n",
    "# RN0  .000125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cfgRN0 = get_cfg()\n",
    "cfgRN0.merge_from_file((\"configs/RN_000125.yaml\"))\n",
    "\n",
    "\n",
    "trainer = DefaultTrainer(cfgRN0)\n",
    "trainer.resume_or_load(resume=True)\n",
    "predictorRN0 = DefaultPredictor(cfgRN0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RN1  .002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cfgRN1 = get_cfg()\n",
    "cfgRN1.merge_from_file((\"configs/RN_002.yaml\"))\n",
    "\n",
    "\n",
    "trainer = DefaultTrainer(cfgRN1)\n",
    "trainer.resume_or_load(resume=True)\n",
    "predictorRN1 = DefaultPredictor(cfgRN1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continue to create as many configurations and predictors as you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#converts coordinates to relative\n",
    "\n",
    "import detectron2.structures.instances as Instances\n",
    "import cv2\n",
    "\n",
    "\n",
    "def absolute_to_rel(bbox, height, width):\n",
    "    bbox[0] =  bbox[0] / width   #x0\n",
    "    bbox[1] =  bbox[1] / height  #y0\n",
    "    bbox[2] =  bbox[2] / width  #x1\n",
    "    bbox[3] =  bbox[3] / height  #y1\n",
    "    \n",
    "    return  (bbox)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Generates a dictionary where keys are boxes, scores and classes\n",
    "# box value is a list of lists of lists - list of coordinates of boxes \n",
    "# for each model's prediction\n",
    "\n",
    "# #score value is a list of lists or a list of lists of score values\n",
    "# classes is a list of lists of classes\n",
    "\n",
    "def preDict(imgPath, predList):\n",
    "    img = cv2.imread(imgPath)\n",
    "    d = {}\n",
    "    \n",
    "    imgID = imgPath.split('/')[-1]\n",
    "    d[\"id\"] = imgID\n",
    "    d[\"boxes\"] = []\n",
    "    d[\"scores\"] = []\n",
    "    d[\"classes\"]= []\n",
    "    \n",
    "    shape = img.shape     #gets a tuple (height, width)\n",
    "    height = shape[0]     #sets height\n",
    "    width = shape[1]      #sets width variable\n",
    "    \n",
    "    for predictor in predList:\n",
    "        x = predictor((img))\n",
    "        tens = x['instances']\n",
    "        numInstances = tens.scores.size()[0]\n",
    "        Boxes = tens.pred_boxes\n",
    "        Boxes = (Boxes.tensor)\n",
    "        Boxes = Boxes.cpu()\n",
    "        Boxes = Boxes.numpy()   #Boxes in numpy array\n",
    "    \n",
    "    \n",
    "        scores = tens.scores\n",
    "        scores = scores.cpu().numpy()    #scores in numpy array\n",
    "    \n",
    "        classes = tens.pred_classes.cpu().numpy()  #classes in numpy array\n",
    "    \n",
    "        Boxes = Boxes.tolist()            #boxes is now a list of lis\n",
    "        scores = scores.tolist()          #now a list\n",
    "        classes = classes.tolist()\n",
    "    \n",
    "\n",
    "\n",
    "        for Box in Boxes:            \n",
    "            Box = absolute_to_rel(Box, height, width)\n",
    "        \n",
    "        d[\"boxes\"].append(Boxes)\n",
    "        d[\"scores\"].append(scores)\n",
    "        d[\"classes\"].append(classes)\n",
    "\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This just tests my pre dict function\n",
    "predictorList = [predictorRN0, predictorRN1, predictorRN2, predictorRN3]\n",
    "for d in valid_img_dicts:\n",
    "    print(preDict((d[\"file_name\"]), predictorList))\n",
    "    print(\"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "def writeCSV(csvFile, predictors):\n",
    "    list = []\n",
    "    for d in valid_img_dicts:\n",
    "        list.append(preDict((d[\"file_name\"]), predictors))\n",
    "    \n",
    "    csv_columns = [\"id\", \"boxes\", \"scores\", \"classes\"]\n",
    "    \n",
    "    try:\n",
    "        with open(csvFile, 'w') as csvfile:\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=csv_columns)\n",
    "            writer.writeheader()\n",
    "            for data in list:\n",
    "                writer.writerow(data)\n",
    "                \n",
    "    except IOError:\n",
    "        print(\"I/o error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writes to output CSV multiple predictions for each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictorList = [predictorRN0, predictorRN1, predictorRN2, predictorRN3]\n",
    "writeCSV(\"predictions_output.csv\", predictorList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writes to output CSV for one prediction for each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictorList = [predictorRN0]\n",
    "writeCSV(\"../customPrecision/mAP/singlePredictionBDM.csv\", predictorList)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
