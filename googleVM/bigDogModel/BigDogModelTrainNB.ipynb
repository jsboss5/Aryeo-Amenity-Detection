{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import  packages!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import Packages\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import cv2\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "torch.__version__\n",
    "!gcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_path = \"train\"\n",
    "valid_path = \"validation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Classes of amenities Airbnb mostly cares about\n",
    "subset = [\"Toilet\",\n",
    "          \"Swimming_pool\",\n",
    "          \"Bed\",\n",
    "          \"Billiard_table\",\n",
    "          \"Sink\",\n",
    "          \"Fountain\",\n",
    "          \"Oven\",\n",
    "          \"Ceiling_fan\",\n",
    "          \"Television\",\n",
    "          \"Microwave_oven\",\n",
    "          \"Gas_stove\",\n",
    "          \"Refrigerator\",\n",
    "          \"Kitchen_&_dining_room_table\",\n",
    "          \"Washing_machine\",\n",
    "          \"Bathtub\",\n",
    "          \"Stairs\",\n",
    "          \"Fireplace\",\n",
    "          \"Pillow\",\n",
    "          \"Mirror\",\n",
    "          \"Shower\",\n",
    "          \"Couch\",\n",
    "          \"Countertop\",\n",
    "          \"Coffeemaker\",\n",
    "          \"Dishwasher\",\n",
    "          \"Sofa_bed\",\n",
    "          \"Tree_house\",\n",
    "          \"Towel\",\n",
    "          \"Porch\",\n",
    "          \"Wine_rack\",\n",
    "          \"Jacuzzi\"]\n",
    "\n",
    "subset.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Replaces underscores with spaces - matches airbnb classes with those from website\n",
    "for i in range(len(subset)):\n",
    "  subset[i] = subset[i].replace(\"_\", \" \")\n",
    "print(subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#convert this list to a string for the command line\n",
    "subset_string = str()\n",
    "for amenity in subset:\n",
    "  subset_string += str(amenity) + \",\"\n",
    "subset_string = subset_string[:len(subset_string)-1]\n",
    "print(subset_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions used to Create Detectron2 Style Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_image_ids(image_folder=None):\n",
    "    \"\"\"\n",
    "    Explores a folder of images and gets their ID from their file name.\n",
    "    Returns a list of all image ID's in image_folder.\n",
    "    E.g. image_folder/608fda8c976e0ac.jpg -> [\"608fda8c976e0ac\"]\n",
    "    \n",
    "    Params\n",
    "    ------\n",
    "    image_folder (str): path to folder of images, e.g. \"../validation/\"\n",
    "    \"\"\"\n",
    "    return [os.path.splitext(img_name)[0] for img_name in os.listdir(image_folder) if img_name.endswith(\".jpg\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make a function which formats a specific annotations csv based on what we're dealing with\n",
    "def format_annotations(image_folder, annotation_file, target_classes=None):\n",
    "    \"\"\"\n",
    "    TODO - NOTE: This function could (definitely can) be faster.\n",
    "    TODO - Some ideas: skip the use of pandas entirely and use CSV's\n",
    "    \n",
    "    Formats annotation_file based on images contained in image_folder.\n",
    "    Will get all unique image IDs and make sure annotation_file\n",
    "    only contains those (the target images).\n",
    "    Adds meta-data to annotation_file such as class names and categories.\n",
    "    If target_classes isn't None, the returned annotations will be filtered by this list.\n",
    "    Note: image_folder and annotation_file should both be validation if working on\n",
    "    validation set or both be training if working on training set.\n",
    "    \n",
    "    Params\n",
    "    ------\n",
    "    image_folder (str): path to folder of target images.\n",
    "    annotation_file (str): path to annotation file of target images.\n",
    "    target_classes (list), optional: a list of target classes you'd like to filter labels.\n",
    "    \"\"\"\n",
    "    # Get all image ids from target directory\n",
    "    image_ids = get_image_ids(image_folder)\n",
    "    \n",
    "    # Setup annotation file and classnames\n",
    "    # TODO - improve this, is pandas required? \n",
    "    annot_file = pd.read_csv(annotation_file)\n",
    "    classes = pd.read_csv(\"class-descriptions-boxable.csv\",\n",
    "                          names=[\"LabelName\", \"ClassName\"])\n",
    "    \n",
    "    # Create classname column on annotations which converts label codes to string labels\n",
    "    annot_file[\"ClassName\"] = annot_file[\"LabelName\"].map(classes.set_index(\"LabelName\")[\"ClassName\"])\n",
    "\n",
    "    # Sort annot_file by \"ClassName\" for alphabetical labels (used with target_classes)\n",
    "    annot_file.sort_values(by=[\"ClassName\"], inplace=True)\n",
    "    \n",
    "    # TODO - fix this, Make sure we only get the images we're concerned about\n",
    "    if target_classes:\n",
    "        annot_file = annot_file[annot_file[\"ImageID\"].isin(image_ids) & annot_file[\"ClassName\"].isin(target_classes)]\n",
    "    else:\n",
    "        annot_file = annot_file[annot_file[\"ImageID\"].isin(image_ids)]\n",
    "   \n",
    "    # Add ClassID column, e.g. \"Bathtub, Toilet\" -> 1, 2\n",
    "    annot_file[\"ClassName\"] = pd.Categorical(annot_file[\"ClassName\"])\n",
    "    annot_file[\"ClassID\"] = annot_file[\"ClassName\"].cat.codes\n",
    "    \n",
    "    return annot_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rel_to_absolute(bbox, height, width):\n",
    "    \"\"\"\n",
    "    Converts bounding box dimensions from relative to absolute pixel values (Detectron2 style).\n",
    "    See: https://detectron2.readthedocs.io/modules/structures.html#detectron2.structures.BoxMode\n",
    "    \n",
    "    Params\n",
    "    ------\n",
    "    bbox (array): relative dimensions of bounding box in format (x0, y0, x1, y1 or Xmin, Ymin, Xmax, Ymax)\n",
    "    height (int): height of image\n",
    "    width (int): width of image\n",
    "    \"\"\"\n",
    "    bbox[0] = np.multiply(bbox[0], width) # x0\n",
    "    bbox[1] = np.multiply(bbox[1], height) # y0\n",
    "    bbox[2] = np.multiply(bbox[2], width) # x1\n",
    "    bbox[3] = np.multiply(bbox[3], height) # y1\n",
    "    #return list(np.round(bbox).astype(float))\n",
    "    return [i.astype(\"object\") for i in bbox] # convert all to objects for JSON saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import CV2 for getting height & width of image\n",
    "import cv2\n",
    "\n",
    "# Import Detectron2 BoxMode for bounding boxes style\n",
    "from detectron2.structures import BoxMode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from detectron2.structures import BoxMode\n",
    "import json\n",
    "import os\n",
    "\n",
    "def get_image_dicts(image_folder, annotation_file, target_classes=None):\n",
    "    \"\"\"\n",
    "    Create JSON of dectectron2 style labels to be reused later.\n",
    "    \n",
    "    TODO -- Maybe create some verbosity here? AKA, what are the outputs?\n",
    "    TODO -- what if annotations = None? Can we create a call to create an annotations CSV in 1 hit?\n",
    "    \n",
    "    Params\n",
    "    ------\n",
    "    image_folder (str): target folder containing images\n",
    "    annotations (DataFrame): DataFrame of image label data\n",
    "    \"\"\"\n",
    "    dataset_name = \"validation\" if \"valid\" in image_folder else \"train\"\n",
    "\n",
    "    print(f\"Using {annotation_file} for annotations...\")\n",
    "    # TODO: there should be some kind of asssertions here making sure the image folder and annotation files match\n",
    "    # E.g. train w/ train and valid w/ valid\n",
    "    annotations = format_annotations(image_folder=image_folder, \n",
    "                                     annotation_file=annotation_file,\n",
    "                                     target_classes=target_classes)\n",
    "\n",
    "    print(f\"On dataset: {dataset_name}\")\n",
    "    print(\"Classes we're using:\\n {}\".format(annotations[\"ClassName\"].value_counts()))\n",
    "\n",
    "    # Get all unique image ids from target folder\n",
    "    img_ids = get_image_ids(image_folder)\n",
    "    print(f\"Total number of images: {len(img_ids)}\")\n",
    "\n",
    "    # TODO: move img_data creation out of for loop and only work with subset of img_ids?\n",
    "    #img_data = annotations[annotations[\"ImageID\"] == img].reset_index() # reset index important for images with multiple objects\n",
    "    #change to something like \"img_data = annotations is in img_ids...\"\n",
    "    \n",
    "    # Start creating image dictionaries (Detectron2 style labelling)\n",
    "    img_dicts = []\n",
    "    for idx, img in enumerate(img_ids):\n",
    "        record = {}\n",
    "        \n",
    "        # Get image metadata\n",
    "        file_name = image_folder + \"/\" + img + \".jpg\"\n",
    "        height, width = cv2.imread(file_name).shape[:2]\n",
    "        img_data = annotations[annotations[\"ImageID\"] == img].reset_index() # reset index important for images\n",
    "                                                                            # with multiple objects\n",
    "        # Verbosity for image label troubleshooting\n",
    "        # print(f\"On image: {img}\")\n",
    "        # print(f\"Image category: {img_data.ClassID.values}\")\n",
    "        # print(f\"Image label: {img_data.ClassName.values}\")\n",
    "\n",
    "        # Update record dictionary\n",
    "        record[\"file_name\"] = file_name\n",
    "        record[\"image_id\"] = idx\n",
    "        record[\"height\"] = height\n",
    "        record[\"width\"] = width\n",
    "        \n",
    "        # Create list of image annotations (labels)\n",
    "        img_annotations = []\n",
    "        for i in range(len(img_data)): # this is where we loop through examples with multiple objects in an image\n",
    "            category_id = img_data.loc[i][\"ClassID\"].astype(\"object\") # JSON (for evalution) can't take int8 (NumPy type) must be native Python type\n",
    "            # print(f\"Image category 2: {category_id}\")\n",
    "            # Get bounding box coordinates in Detectron2 style (x0, y0, x1, y1)\n",
    "            bbox = np.float32(img_data.loc[i][[\"XMin\", \"YMin\", \"XMax\", \"YMax\"]].values) # needs to be float/int # TODO: change for JSON\n",
    "            # Convert bbox from relative to absolute pixel dimensions\n",
    "            bbox = rel_to_absolute(bbox=bbox, height=height, width=width)\n",
    "            # Setup annot (1 annot = 1 label, there might be more) dictionary\n",
    "            annot = {\n",
    "                \"bbox\": bbox, \n",
    "                \"bbox_mode\": BoxMode.XYXY_ABS, # See: https://detectron2.readthedocs.io/modules/structures.html#detectron2.structures.BoxMode.XYXY_ABS\n",
    "                \"category_id\": category_id\n",
    "            }\n",
    "            img_annotations.append(annot)\n",
    "            \n",
    "        # Update record dictionary with annotations\n",
    "        record[\"annotations\"] = img_annotations\n",
    "        \n",
    "        # Add record dictionary with image annotations to img_dicts list\n",
    "        img_dicts.append(record)\n",
    "\n",
    "    # TODO: Change this into it's own function??\n",
    "    # Save img_dicts to JSON for use later\n",
    "    json_file = os.path.join(image_folder, dataset_name+\"_labels.json\")\n",
    "    print(f\"Saving labels to: {json_file}...\")\n",
    "    with open(json_file, \"w\") as f:\n",
    "      json.dump(img_dicts, f)\n",
    "\n",
    "    # return img labels dictionary\n",
    "    return img_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_json_labels(image_folder):\n",
    "    \"\"\"\n",
    "    Returns Detectron2 style labels of images in image_folder based on JSON label file in image_folder.\n",
    "    \n",
    "    TODO -- Maybe create some verbosity here? AKA, what are the outputs?\n",
    "    TODO -- what if annotations = None? Can we create a call to create an annotations CSV in 1 hit?\n",
    "    \n",
    "    Params\n",
    "    ------\n",
    "    image_folder (str): target folder containing images\n",
    "    \"\"\"\n",
    "    # Get absolute path of JSON label file\n",
    "    for file in os.listdir(image_folder):\n",
    "      if file.endswith(\".json\"):\n",
    "        json_file = os.path.join(image_folder, file)\n",
    "\n",
    "    # TODO: Fix this assertion\n",
    "    assert json_file, \"No .json label file found, please make one with annots_to_json()\"\n",
    "\n",
    "    with open(json_file, \"r\") as f:\n",
    "      img_dicts = json.load(f)\n",
    "\n",
    "    # Convert bbox_mode to Enum of BoxMode.XYXY_ABS (doesn't work loading normal from JSON)\n",
    "    for img_dict in img_dicts:\n",
    "      for annot in img_dict[\"annotations\"]:\n",
    "        annot[\"bbox_mode\"] = BoxMode.XYXY_ABS\n",
    "\n",
    "    return img_dicts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Only create the labels from scratch once (only call get_image_dicts once) Every subsequent time use the json loader to load the saved labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating Lables from scratch\n",
    "%%time\n",
    "valid_img_dicts = get_image_dicts(valid_path, \n",
    "                                  \"validation-annotations-bbox.csv\",\n",
    "                                  target_classes=subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating labels from scratch\n",
    "%%time\n",
    "train_img_dicts = get_image_dicts(train_path, \n",
    "                                  \"train-annotations-bbox.csv\",\n",
    "                                  target_classes=subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loading saved json file labels\n",
    "valid_img_dicts = load_json_labels(\"validation\")\n",
    "train_img_dicts = load_json_labels(\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Look at how many unique categories are there\n",
    "unique_cats = []\n",
    "for dicty in train_img_dicts:\n",
    "  unique_cats.append(dicty[\"annotations\"][0][\"category_id\"])\n",
    "print(f\"Unique categories in train_img_dicts: {set(unique_cats)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Register Data set, and visualize labels to ensure everything looks good before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "\n",
    "def register_datasets(train_path, valid_path=None, target_classes=None):\n",
    "  \"\"\"\n",
    "  Registers a Detectron2 style dataset from training paths.\n",
    "\n",
    "  Params\n",
    "  ------\n",
    "  train_path (str) : pathname to training data containing training images\n",
    "  valid_path (str) : pathname to validation data containing validation images\n",
    "  \"\"\"\n",
    "  # TODO - update to accept any kind of path, e.g. not only coffeemaker, maybe could take a dict as input?\n",
    "  # E.g. {\"training\": \"path/to/training\",\n",
    "  #          \"valid\": \"path/to/valid\"}\n",
    "  for d in [train_path, valid_path]:\n",
    "    dataset_name = d.split(\"/\")[-1]\n",
    "    print(\"Registering: {}\".format(dataset_name))\n",
    "    DatasetCatalog.register(dataset_name, lambda d=d: load_json_labels(d))\n",
    "    MetadataCatalog.get(dataset_name).set(thing_classes=target_classes)\n",
    "  return MetadataCatalog.get(dataset_name)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metadata = register_datasets(train_path=train_path,\n",
    "                             valid_path=valid_path,\n",
    "                             target_classes=subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "big_metadata = MetadataCatalog.get(\"validation\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from detectron2.utils.visualizer import Visualizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "def visualize_sample(data_dicts, metadata, n=1):\n",
    "  \"\"\"\n",
    "  Show n random samples from data_dicts, label with metadata.\n",
    "  \"\"\"\n",
    "  for d in random.sample(data_dicts, n):\n",
    "    print(d)\n",
    "    img = cv2.imread(d[\"file_name\"])\n",
    "    visualizer = Visualizer(img[:, :, ::-1],\n",
    "                            metadata=metadata,\n",
    "                            scale=0.3)\n",
    "    vis = visualizer.draw_dataset_dict(d)\n",
    "#     # Try plot with cv2 in Jupyter... (doesn't work)\n",
    "#     cv2.imshow('image', vis.get_image()[:, :, ::-1])\n",
    "#     cv2.waitKey(0)\n",
    "#     cv2.destroyWindow('image')\n",
    "    # Try plot with matplotlib (works)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.imshow(vis.get_image()) #[:, :, ::-1])\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "visualize_sample(valid_img_dicts, \n",
    "                 big_metadata, \n",
    "                 n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set configurations for training - and Train!... and wait! and wait some more!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.config import get_cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/retinanet_R_101_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"train\",)\n",
    "cfg.DATASETS.TEST = ()\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/retinanet_R_101_FPN_3x.yaml\")  # Let training initialize from model zoo\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "cfg.SOLVER.BASE_LR = 0.000125  # pick a good LR\n",
    "cfg.SOLVER.MAX_ITER = 180000    # 300 iterations seems good enough for this toy dataset; you may need to train longer for a practical dataset\n",
    "cfg.SOLVER.WARMUP_ITERS = 2000\n",
    "cfg.SOLVER.STEPS = (120000,160000)\n",
    "\n",
    "\n",
    "#cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128   # faster, and good enough for this toy dataset (default: 512)\n",
    "cfg.MODEL.RETINANET.NUM_CLASSES = 30  # Has three classes\n",
    "\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = DefaultTrainer(cfg) \n",
    "trainer.resume_or_load(resume=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use COCOEvaluator to asses Mean Average Precision of Model, and AP of each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "cfg.MODEL.RETINANET.SCORE_THRESH_TEST = 0.7   # set the testing threshold for this model\n",
    "cfg.DATASETS.TEST = (\"validation\", )\n",
    "predictor = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "evaluator = COCOEvaluator(\"validation\", cfg, False, output_dir=\"./output/\")\n",
    "val_loader = build_detection_test_loader(cfg, \"validation\")\n",
    "inference_on_dataset(trainer.model, val_loader, evaluator)\n",
    "# another equivalent way is to use trainer.test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# and Visualize to triple check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from detectron2.utils.visualizer import ColorMode\n",
    "#dataset_dicts = get_balloon_dicts(\"balloon/val\")\n",
    "%matplotlib inline\n",
    "for d in random.sample(valid_img_dicts, 1):    \n",
    "    im = cv2.imread(d[\"file_name\"])\n",
    "    outputs = predictor(im)\n",
    "    print(outputs)\n",
    "    v = Visualizer(im[:, :, ::-1],\n",
    "                   metadata=big_metadata, \n",
    "                   scale=0.5 \n",
    "                   #instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels\n",
    "    )\n",
    "    v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.imshow(v.get_image()) #[:, :, ::-1])\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.show()\n",
    "    #cv2_imshow(v.get_image()[:, :, ::-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
